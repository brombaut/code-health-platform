{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30841e0-9ae8-472d-8168-b172879b89cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisits\n",
    "- CodeMaat (installed on PATH or have the JAR present)\n",
    "- Java (required by CodeMaat)\n",
    "- cloc \n",
    "- Python 3.9 or higher\n",
    "- Either have internet connectiona dn use d3 cdn or follow the steps at https://stackoverflow.com/questions/43234410/how-can-i-load-external-static-javascript-files-in-ipython-or-jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9ab5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shlex\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from IPython.display import clear_output, display, Javascript, HTML\n",
    "\n",
    "from ipynb.fs.full.cs_filepaths import FilePaths\n",
    "from ipynb.fs.full.cs_entities import ProjectForAnalysis, SystemBoundaries, AuthorColor\n",
    "from ipynb.fs.full.cs_d3graphing import EnclosureDiagram, MainDevEnclosureDiagram\n",
    "from ipynb.fs.full.cs_commands import (\n",
    "    GitLogCommand, MaatCommand, ClocCommand, MergeComplexityAndFrequency, \n",
    "    FileComplexityCommand, FileComplexityTrendCommand,\n",
    "    CreateEnclosureDiagramJson, CreateMainDevEnclosureDiagramJson\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec8d69",
   "metadata": {},
   "source": [
    "## Analysis Types\n",
    "\n",
    "The primary classes that represent each type of analysis.\n",
    "\n",
    "<!-- - [HotspotAnalysis](#HotspotAnalysis)\n",
    "- [FileComplexityStaticAnalysis](#FileComplexityStaticAnalysis)\n",
    "- [FileComplexityTrendAnalysis](#FileComplexityTrendAnalysis) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc509f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis:\n",
    "    def __init__(self, project_for_analysis):\n",
    "        self.project_for_analysis = project_for_analysis\n",
    "        self.file_paths = FilePaths()\n",
    "        \n",
    "    def _generate_log_file(self):\n",
    "        # Generate log file\n",
    "        log_command = GitLogCommand(\n",
    "            self.project_for_analysis.git_file,\n",
    "            before=self.project_for_analysis.before,\n",
    "            after=self.project_for_analysis.after\n",
    "        )\n",
    "        log_command.execute().write_out_to_file()\n",
    "        \n",
    "    def df(self):\n",
    "        raise Exception(\"Method not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1092896",
   "metadata": {},
   "source": [
    "### HotspotAnalysis\n",
    "\n",
    "Examines a project's files by extracting their revision frequency (as a proxy for effort expended on the module) and line count (as a proxy for complexity) in order to detect hotspots in your codebase. Either view the data in a dataframe or visualize the project with an enclosure diagram.\n",
    "\n",
    "- `module`: The file in question\n",
    "- `revisions`: The number of revisions that module has undergone in the analysis timespan\n",
    "- `code`: The number of lines of code in the module (as a proxy for complexity)\n",
    "\n",
    "Example\n",
    "```python\n",
    "code_maat = ProjectForAnalysis(\"/home/brombaut/work/code-maat\")\n",
    "hs_analysis = HotspotAnalysis(code_maat)\n",
    "hs_analysis.analyze()\n",
    "df = hs_analysis.df()\n",
    "# Show enclosure diagram\n",
    "hs_analysis.enclosure_diagram()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1a4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class HotspotAnalysis(Analysis):\n",
    "    def __init__(self, project_for_analysis):\n",
    "        super().__init__(project_for_analysis)\n",
    "        \n",
    "    def analyze(self):\n",
    "        self._generate_log_file()\n",
    "        # Analyze Change Frequencies\n",
    "        self.maat_command = (\n",
    "            MaatCommand(f\"-l {self.file_paths.log_file} -c git -a revisions\")\n",
    "                .execute()\n",
    "                .write_out_to_file()\n",
    "        )\n",
    "        # Count Lines of Code\n",
    "        self.cloc_command = (\n",
    "            ClocCommand(f\"{self.project_for_analysis.dir_to_analyze} --by-file --csv --quiet\")\n",
    "                .execute()\n",
    "                .write_out_to_file()\n",
    "        )\n",
    "        # Merge Complexity and Effort for Data View\n",
    "        self.merge_command = (\n",
    "            MergeComplexityAndFrequency(\n",
    "                self.file_paths.maat_output_csv, self.file_paths.cloc_lines_csv\n",
    "            ).execute()\n",
    "        )\n",
    "        # Create Enclosure JSON\n",
    "        self.create_enclosure_json_command = CreateEnclosureDiagramJson(\n",
    "            self.file_paths.maat_output_csv, self.file_paths.cloc_lines_csv)\n",
    "        self.create_enclosure_json_command.execute()\n",
    "        # Just write to file incase its needed for manual work\n",
    "        self.create_enclosure_json_command.write_out_to_file()\n",
    "        return self\n",
    "        \n",
    "    def enclosure_diagram(self):\n",
    "        enclosure_diagram_json = json.loads(self.create_enclosure_json_command.out_as_str())\n",
    "        enc_diagram = EnclosureDiagram(enclosure_diagram_json)\n",
    "        enc_diagram.show()\n",
    "        return self\n",
    "    \n",
    "    def df(self):\n",
    "        result = pd.read_csv(StringIO(self.merge_command.out_as_str()))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce0057",
   "metadata": {},
   "source": [
    "### Complexity Analysis (Whitespace Analysis)\n",
    "\n",
    "The idea of indentation as a proxy for complexity is backed by research (see [Reading Beside the Lines: Indentation as a Proxy for Complexity Metric](https://www.semanticscholar.org/paper/Reading-Beside-the-Lines%3A-Indentation-as-a-Proxy-Hindle-Godfrey/ce39dfa1f8b0b234da54c6f4b696e28057fc2b20)). It's a simple metric, yet it correlates with more elaborate metrics, such as McCabe cyclomatic complexity and Halstead complexity measures.\n",
    "\n",
    "We can either perform this analysis on a single snapshot in time of a file (`StaticFileComplexityAnalysis`), or (perhaps more useful) we can perform this analysis on a file across time to visualize the complexity trend of the file (`TrendFileComplexityAnalysis`).\n",
    "\n",
    "We are basically the calculating the logical indentation for a static file. Four spaces or one tab counts as one logical indentation. Empty and blank lines are ignored.\n",
    "\n",
    "- The `total` column is the accumulated complexity. Itâ€™s useful to compare different revisions or modules against each other.\n",
    "- The `mean` column tells us the mean complexity of the module.\n",
    "- The standard deviation `sd` column tells us the variance of the complexity within the module. A low number indicates that most lines have a complexity close to the mean.\n",
    "- The `max` columns show the maximum complexity value in the module. A large maximum indentation value means there is a lot of indenting, which essentially means nested conditions. We can expect islands of complexity.\n",
    "\n",
    "> [REVIEW THIS] Note that in order to specify the timespan for analysis, you must provide a `before` and/or `after` value when creating the `ProjectForAnalysis`. These values are used to determine the commits to use when calculating the complexity trend\n",
    "\n",
    "Example\n",
    "\n",
    "```python\n",
    "benrombautca = ProjectForAnalysis(\"/home/brombaut/work/benrombautca\")\n",
    "\n",
    "# Static analysis\n",
    "static_file_complexity = StaticFileComplexityAnalysis(benrombautca, \"src/bookshelf/BookCard.vue\")\n",
    "static_file_complexity.analyze()\n",
    "df = static_file_complexity.df()\n",
    "\n",
    "# Trend analysis\n",
    "file_complexity_trend = TrendFileComplexityAnalysis(benrombautca, \"src/bookshelf/BookCard.vue\")\n",
    "file_complexity_trend.analyze()\n",
    "df = file_complexity_trend.df()\n",
    "# Show trend lines\n",
    "file_complexity_trend.total_trend_line_plot()\n",
    "file_complexity_trend.mean_trend_line_plot()\n",
    "file_complexity_trend.sd_trend_line_plot()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc384fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileComplexityAnalysis(Analysis):\n",
    "    def __init__(self, project_for_analysis, file_name_for_analysis):\n",
    "        super().__init__(project_for_analysis)\n",
    "        project_for_analysis.throw_if_file_does_not_exist(file_name_for_analysis)\n",
    "        self.file_name_for_analysis = file_name_for_analysis\n",
    "\n",
    "        \n",
    "class StaticFileComplexityAnalysis(FileComplexityAnalysis):        \n",
    "    def analyze(self):\n",
    "        comp_analysis_command = FileComplexityCommand(\n",
    "            f\"{self.project_for_analysis.dir_to_analyze}/{self.file_name_for_analysis}\"\n",
    "        ).execute()\n",
    "        self.csv_str = comp_analysis_command.out_as_str()\n",
    "        return self\n",
    "        \n",
    "    def df(self):\n",
    "        result = pd.read_csv(StringIO(self.csv_str))\n",
    "        return result\n",
    "\n",
    "    \n",
    "class TrendFileComplexityAnalysis(FileComplexityAnalysis):\n",
    "    def analyze(self):\n",
    "        self.comp_analysis_command = FileComplexityTrendCommand(\n",
    "            self.project_for_analysis.dir_to_analyze,\n",
    "            self.file_name_for_analysis,\n",
    "            self.project_for_analysis.first_commit_in_timespan(),\n",
    "            self.project_for_analysis.last_commit_in_timespan(),\n",
    "        ).execute()\n",
    "        return self\n",
    "    \n",
    "    def df(self):\n",
    "        result = pd.read_csv(StringIO(self.comp_analysis_command.out_as_str()))\n",
    "        return result\n",
    "    \n",
    "    def line_plot(self, y):\n",
    "        self.df().plot.line(\n",
    "            y=y,\n",
    "            title=self.file_name_for_analysis,\n",
    "            ylabel=f\"Complexity ({y})\",\n",
    "            xlabel=\"Revision\",\n",
    "        )\n",
    "    \n",
    "    def total_trend_line_plot(self):\n",
    "        self.line_plot(\"total\")\n",
    "        return self\n",
    "    \n",
    "    def mean_trend_line_plot(self):\n",
    "        self.line_plot(\"mean\")\n",
    "        return self\n",
    "    \n",
    "    def sd_trend_line_plot(self):\n",
    "        self.line_plot(\"sd\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc97dc05",
   "metadata": {},
   "source": [
    "## Coupling Analysis\n",
    "\n",
    "Generates the following fields:\n",
    "\n",
    "1. entity: This is the name of one of the involved modules. Code Maat always calculates pairs.\n",
    "2. coupled: This is the coupled counterpart to the entity.\n",
    "3. degree: The degree specifies the percent of shared commits. The higher the number, the stronger the coupling.\n",
    "4. average-revs: Finally, we get a weighted number of total revisions for the involved modules. The idea here is that we can filter out modules with too few revisions to avoid bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa96a5",
   "metadata": {},
   "source": [
    "### SystemCouplingAnalysis\n",
    "\n",
    "Example\n",
    "```python\n",
    "boundaries_dict = {\n",
    "    \"Code\": [\"src/code_maat\"],\n",
    "    \"Analysis Test\": [\"test/code_maat/analysis\"],\n",
    "    \"Dataset Test\": [\"test/code_maat/dataset\"],\n",
    "    \"End to end Test\": [\"test/code_maat/end_to_end\"],\n",
    "    \"Parsers Test\": [\"test/code_maat/parsers\"],\n",
    "}\n",
    "boundaries = SystemBoundaries(boundaries_dict)\n",
    "craft = ProjectForAnalysis(\"/home/brombaut/work/code-maat\", system_boundaries=boundaries)\n",
    "coupling_data = SystemCouplingAnalysis(craft).analyze().df()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06dacfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Should this handle architectural boundaries?\n",
    "class SystemCouplingAnalysis(Analysis):\n",
    "    # NOTE: temporal_period can only be None or 1 (limitation of codemaat)\n",
    "    def __init__(self, project_for_analysis, temporal_period=None):\n",
    "        super().__init__(project_for_analysis)\n",
    "        self.temporal_period = temporal_period\n",
    "        \n",
    "    def analyze(self):\n",
    "        self._generate_log_file()\n",
    "        # Analyze Coupling\n",
    "        cmd_str = f\"-l {self.file_paths.log_file} -c git -a coupling\"\n",
    "        if self.project_for_analysis.has_system_boundaries():\n",
    "            cmd_str += f\" -g {self.project_for_analysis.system_boundaries_file()}\"\n",
    "        if self.temporal_period:\n",
    "            cmd_str += f\" --temporal-period {self.temporal_period}\"\n",
    "        self.maat_command = MaatCommand(cmd_str).execute()\n",
    "        return self\n",
    "    \n",
    "    def df(self):\n",
    "        result = pd.read_csv(StringIO(self.maat_command.out_as_str()))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058845fd",
   "metadata": {},
   "source": [
    "### FileCouplingAnalysis\n",
    "\n",
    "Example\n",
    "\n",
    "```python\n",
    "benrombautca = ProjectForAnalysis(\"/home/brombaut/work/benrombautca\")\n",
    "file_coupling_analysis = FileCouplingAnalysis(benrombautca, \"src/bookshelf/BookshelfSection.vue\")\n",
    "file_coupling_analysis.analyze()\n",
    "file_coupling_analysis.enclosure_diagram()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05c6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileCouplingAnalysis(Analysis):\n",
    "    def __init__(self, project_for_analysis, file_name_for_analysis):\n",
    "        super().__init__(project_for_analysis)\n",
    "        project_for_analysis.throw_if_file_does_not_exist(file_name_for_analysis)\n",
    "        self.file_name_for_analysis = file_name_for_analysis\n",
    "        \n",
    "    def analyze(self):\n",
    "        self._generate_log_file()\n",
    "        # Analyze Coupling\n",
    "        self.maat_command = (\n",
    "            MaatCommand(f\"-l {self.file_paths.log_file} -c git -a coupling\")\n",
    "                .execute()\n",
    "                .write_out_to_file()\n",
    "        )\n",
    "        # Count Lines of Code\n",
    "        self.cloc_command = (\n",
    "            ClocCommand(f\"{self.project_for_analysis.dir_to_analyze} --by-file --csv --quiet\")\n",
    "                .execute()\n",
    "                .write_out_to_file()\n",
    "        )\n",
    "        # Filter only lines with specific file\n",
    "        df = pd.read_csv(self.file_paths.maat_output_csv)\n",
    "        self.filtered_df = df.loc[\n",
    "            (df['entity'].str.contains(self.file_name_for_analysis)) |\n",
    "            (df['coupled'].str.contains(self.file_name_for_analysis))\n",
    "        ]\n",
    "        if len(self.filtered_df) == 0:\n",
    "            raise Exception(f\"No coupling data detected for file={self.file_name_for_analysis}\")\n",
    "        self.filtered_df.to_csv(self.file_paths.maat_output_csv, index=False)\n",
    "        # Create Enclosure JSON\n",
    "        self.create_enclosure_json_command = CreateEnclosureDiagramJson(\n",
    "            self.file_paths.maat_output_csv,\n",
    "            self.file_paths.cloc_lines_csv,\n",
    "            weight_column=2\n",
    "        ).execute()\n",
    "        return self\n",
    "        \n",
    "    def enclosure_diagram(self):            \n",
    "        enclosure_diagram_json = json.loads(self.create_enclosure_json_command.out_as_str())\n",
    "        enc_diagram = EnclosureDiagram(enclosure_diagram_json)\n",
    "        enc_diagram.show()\n",
    "        return self\n",
    "    \n",
    "    def df(self):\n",
    "        return self.filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e2d75",
   "metadata": {},
   "source": [
    "## Authors Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6869a2b",
   "metadata": {},
   "source": [
    "### ParallelWorkAnalysis\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "craft = ProjectForAnalysis(\"/home/brombaut/work/code-maat\")\n",
    "an = ParallelWorkAnalysis(craft)\n",
    "an.analyze()\n",
    "an.df()\n",
    "an.enclosure_diagram()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54dad637",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelWorkAnalysis(Analysis):\n",
    "    def __init__(self, project_for_analysis):\n",
    "        super().__init__(project_for_analysis)\n",
    "        \n",
    "    def analyze(self):\n",
    "        self._generate_log_file()\n",
    "        # Analyze Change Frequencies\n",
    "        self.maat_command = (\n",
    "            MaatCommand(f\"-l {self.file_paths.log_file} -c git -a authors\")\n",
    "                .execute()\n",
    "                .write_out_to_file()\n",
    "        )\n",
    "        # Count Lines of Code\n",
    "        self.cloc_command = (\n",
    "            ClocCommand(f\"{self.project_for_analysis.dir_to_analyze} --by-file --csv --quiet\")\n",
    "                .execute()\n",
    "                .write_out_to_file()\n",
    "        )\n",
    "        # Create Enclosure JSON\n",
    "        self.create_enclosure_json_command = CreateEnclosureDiagramJson(\n",
    "            self.file_paths.maat_output_csv,\n",
    "            self.file_paths.cloc_lines_csv,\n",
    "            weight_column=1\n",
    "        ).execute()\n",
    "        return self\n",
    "        \n",
    "    def enclosure_diagram(self):\n",
    "        enclosure_diagram_json = json.loads(self.create_enclosure_json_command.out_as_str())\n",
    "        enc_diagram = EnclosureDiagram(enclosure_diagram_json)\n",
    "        enc_diagram.show()\n",
    "        return self\n",
    "    \n",
    "    def df(self):\n",
    "        result = pd.read_csv(StringIO(self.maat_command.out_as_str()))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54c1a7",
   "metadata": {},
   "source": [
    "### MainDeveloperAnalysis\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "code_maat = ProjectForAnalysis(\"/home/brombaut/work/code-maat\")\n",
    "an = MainDeveloperAnalysis(code_maat)\n",
    "an.analyze()\n",
    "an.df()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7edfd4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainDeveloperAnalysis(Analysis):\n",
    "    def __init__(self, project_for_analysis):\n",
    "        super().__init__(project_for_analysis)\n",
    "        \n",
    "    def analyze(self):\n",
    "        self._generate_log_file()\n",
    "        # Analyze Change Frequencies\n",
    "        self.maat_command = (\n",
    "            MaatCommand(f\"-l {self.file_paths.log_file} -c git -a main-dev\")\n",
    "                .execute()\n",
    "        )\n",
    "        # Count Lines of Code\n",
    "        self.cloc_command = (\n",
    "            ClocCommand(f\"{self.project_for_analysis.dir_to_analyze} --by-file --csv --quiet\")\n",
    "                .execute()\n",
    "                .write_out_to_file()\n",
    "        )\n",
    "\n",
    "    def df(self):\n",
    "        result = pd.read_csv(StringIO(self.maat_command.out_as_str()))\n",
    "        return result\n",
    "    \n",
    "    def enclosure_diagram(self, author_colors=None):\n",
    "        if author_colors is None:\n",
    "            author_colors = AuthorColor.from_authors_list(self.df()['main-dev'].unique())\n",
    "        # Rewrite out to file\n",
    "        self.maat_command.write_out_to_file()\n",
    "        self.cloc_command.write_out_to_file()\n",
    "        author_colors.write_to_file()\n",
    "        # Create main dev enclosure diagram json\n",
    "        self.create_main_dev_enclosure_json_command = (\n",
    "            CreateMainDevEnclosureDiagramJson(\n",
    "                self.cloc_command.out_file(),\n",
    "                self.maat_command.out_file(),\n",
    "                author_colors.out_file()\n",
    "            ).execute()\n",
    "        )\n",
    "        enclosure_diagram_json = json.loads(self.create_main_dev_enclosure_json_command.out_as_str())\n",
    "        self.data = enclosure_diagram_json\n",
    "        enc_diagram = MainDevEnclosureDiagram(enclosure_diagram_json)\n",
    "        enc_diagram.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d7d7f",
   "metadata": {},
   "source": [
    "### EntityOwnershipAnalysis\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "code_maat = ProjectForAnalysis(\"/home/brombaut/work/code-maat\")\n",
    "an = EntityOwnershipAnalysis(craft)\n",
    "an.analyze()\n",
    "an.df()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733dd9db-8d79-4f8c-9d7b-2876d798730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityOwnershipAnalysis(Analysis):\n",
    "    def __init__(self, project_for_analysis):\n",
    "        super().__init__(project_for_analysis)\n",
    "        \n",
    "    def analyze(self):\n",
    "        self._generate_log_file()\n",
    "        # Analyze Change Frequencies\n",
    "        self.maat_command = (\n",
    "            MaatCommand(f\"-l {self.file_paths.log_file} -c git -a entity-ownership\")\n",
    "                .execute()\n",
    "        )\n",
    "        \n",
    "    def df(self):\n",
    "        result = pd.read_csv(StringIO(self.maat_command.out_as_str()))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbfa08-9bae-4462-b366-6865e33ed8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fractal figures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac21b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9f225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c773e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e662897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77ebe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
